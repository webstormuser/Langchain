{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gettting started with GROQ_API \n",
    "* GROQ_API is a free api you can use to call your LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API Key: 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\n"
     ]
    }
   ],
   "source": [
    "# Fetch the Groq API key\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "print(f\"Loaded API Key: {groq_api_key}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model used is The Gemma 2-9B IT \n",
    "* model is a large language model developed by Google and supported by Groq1\n",
    "* Here are some key details about it:\n",
    "* Developer: Google1\n",
    "* Model Size: 9 billion parameters1\n",
    "* Context Window: 8,192 tokens2\n",
    "* Use Cases: Text generation, question answering, summarization, and reasoning1\n",
    "* Performance: Designed for high performance and efficiency, making it suitable for both online and offline applications3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002021D9EA3B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002021DA18100>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "# Initialize Groq API client with the new API key\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building simple LLM ,Prompt and StroutputCHains with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    SystemMessage(content=\"You are helpful assistant. PLease provide me clar and concise answer for question asked\"),\n",
    "    HumanMessage(content=\"What is Langchain?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are helpful assistant. PLease provide me clar and concise answer for question asked', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is Langchain?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is a framework for developing applications powered by large language models (LLMs). \\n\\nThink of it as a toolbox that helps you build with LLMs like ChatGPT in a more structured and powerful way.  \\n\\nIt provides:\\n\\n* **Building blocks:** Components for tasks like prompting, memory, and chaining together different LLMs.\\n* **Integration:**  Connects LLMs to other data sources and tools (databases, APIs, etc.).\\n* **Workflows:**  Structures your LLM interactions into clear, reusable workflows.\\n\\n\\nEssentially, LangChain makes it easier to build sophisticated applications that leverage the capabilities of LLMs.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 30, 'total_tokens': 162, 'completion_time': 0.24, 'prompt_time': 0.000135429, 'queue_time': 0.014053091, 'total_time': 0.240135429}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-de5fe234-59ea-4776-a355-137e9dd6bd5c-0', usage_metadata={'input_tokens': 30, 'output_tokens': 132, 'total_tokens': 162})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is a framework for developing applications powered by large language models (LLMs). \\n\\nThink of it as a toolbox filled with components that help you build sophisticated LLM-powered applications. \\n\\nThese components include:\\n\\n* **Prompt Templates:**  Structured ways to input information to LLMs for better results.\\n* **Chains:** Sequences of LLMs and other tools working together to accomplish a complex task.\\n* **Memory:**  Allows LLMs to remember past interactions in a conversation.\\n* **Agents:**  LLMs that can autonomously choose actions and interact with their environment.\\n\\n\\nEssentially, LangChain simplifies the process of using LLMs by providing the building blocks and tools you need to create powerful and customized applications. \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 154, 'prompt_tokens': 30, 'total_tokens': 184, 'completion_time': 0.28, 'prompt_time': 0.000144779, 'queue_time': 0.013584991000000001, 'total_time': 0.280144779}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-efa0aff6-9b21-4493-a7b0-26ab6b33ba27-0', usage_metadata={'input_tokens': 30, 'output_tokens': 154, 'total_tokens': 184})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=model.invoke(messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a framework for developing applications powered by large language models (LLMs). \\n\\nThink of it as a toolbox filled with components that help you build sophisticated LLM-powered applications. \\n\\nThese components include:\\n\\n* **Prompt Templates:**  Structured ways to input information to LLMs for better results.\\n* **Chains:** Sequences of LLMs and other tools working together to accomplish a complex task.\\n* **Memory:**  Allows LLMs to remember past interactions in a conversation.\\n* **Agents:**  LLMs that can autonomously choose actions and interact with their environment.\\n\\n\\nEssentially, LangChain simplifies the process of using LLMs by providing the building blocks and tools you need to create powerful and customized applications. \\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By using output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system message\n",
    "system_message = SystemMessage(content=\"You are a helpful assistant. Please respond to questions clearly and concisely.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to ask question from user \n",
    "def ask_question(question):\n",
    "    human_message=HumanMessage(content=f\"question:{question}\")\n",
    "    message=[system_message,human_message]\n",
    "    response=model.invoke(message)\n",
    "    response = response.content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langchain is a framework for developing applications powered by large language models (LLMs).  \\n\\nThink of it as a toolbox that helps you:\\n\\n* **Connect LLMs to other data sources:**  It lets you use LLMs with your own databases, APIs, and files.\\n* **Chain together different LLMs and tools:**  You can build complex workflows by combining multiple LLMs and other tools.\\n* **Manage LLM prompts and responses:** Langchain provides tools for creating effective prompts and handling the outputs from LLMs. \\n\\n\\nEssentially, Langchain makes it easier to build practical and powerful applications using the capabilities of LLMs.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"What is Langchain?\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A Turing Machine is a theoretical model of computation that defines an abstract machine capable of performing any computation that a modern computer can, given enough time and memory.  \\n\\nHere's a detailed explanation:\\n\\n**Core Components:**\\n\\n* **Tape:** An infinitely long strip divided into cells, each capable of holding a single symbol from a finite alphabet.\\n* **Head:** A read/write head that can move left or right along the tape, reading and writing symbols.\\n* **State Register:** Holds the current state of the machine, which determines its actions.\\n* **Transition Function:** A set of rules that dictate the machine's behavior. Each rule specifies:\\n    * The current state.\\n    * The symbol read by the head.\\n    * The symbol to write in that cell.\\n    * The direction to move the head (left, right, or stay).\\n    * The new state to transition to.\\n\\n**How it Works:**\\n\\n1. The machine starts in a designated initial state with an input string written on the tape.\\n2. The head reads the first symbol on the tape.\\n3. Based on the current state and the read symbol, the transition function determines the next action:\\n    * Write a symbol to the current cell.\\n    * Move the head left or right.\\n    * Transition to a new state.\\n4. This process repeats, with the machine following the transition function's instructions until it reaches a designated halting state.\\n5. The contents of the tape at that point represent the result of the computation.\\n\\n**Universal Computation:**\\n\\nThe beauty of the Turing Machine is its universality.  Any algorithm that can be expressed as a set of instructions can be simulated by a Turing Machine.  This means it can theoretically solve any computational problem solvable by any computer.\\n\\n**Limitations:**\\n\\n* **Theoretical:** Turing Machines are abstract models and don't exist as physical machines.\\n* **Infinite Tape:** The concept of an infinite tape is impractical for real-world implementation.\\n* **Time & Space Complexity:**  While Turing Machines can solve any problem, some problems might require an impractically long time or an enormous amount of tape to solve.\\n\\n**Significance:**\\n\\nDespite its theoretical nature, the Turing Machine is a cornerstone of computer science. It:\\n\\n* **Formalizes the concept of computation:**  Provides a clear definition of what it means to compute.\\n* **Establishes the limits of computation:**  Defines problems that are undecidable (unsolvable by any algorithm).\\n* **Underpins the design of modern computers:**  The principles of computation embodied in Turing Machines are reflected in the architecture and operation of modern computers.\\n\\n\\nLet me know if you have any more questions!\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"What is Turing Machine please explain in detail?\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    # Create a human message\n",
    "    human_message = HumanMessage(content=f\"Question: {question}\")\n",
    "    \n",
    "    # Combine the messages\n",
    "    messages = [system_message, human_message]\n",
    "    \n",
    "    # Generate response using the model\n",
    "    try:\n",
    "        response = model.invoke(messages)\n",
    "        # Extract and return the content, removing extra newline characters\n",
    "        cleaned_response = response.content.replace(\"\\n\", \" \").strip()\n",
    "        return cleaned_response\n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A Turing Machine is a theoretical model of computation, often considered the foundation of modern computer science.   Here's a detailed explanation:  **Core Components:**  * **Tape:** An infinitely long strip divided into cells, each capable of holding a single symbol from a finite alphabet. * **Head:** A read/write mechanism that can move left or right along the tape, reading and writing symbols in the cells. * **State Register:** Holds the current state of the machine, which can be one of a finite set of states. * **Transition Function:** A set of rules that dictate the machine's behavior. Each rule specifies:     * The current state     * The symbol read from the tape     * The symbol to be written to the tape     * The new state     * The direction to move the head (left or right)  **How it Works:**  1. **Initialization:** The machine starts in a designated initial state with an input string on the tape. 2. **Execution:** The machine reads the symbol under the head, consults the transition function to determine its next action, and performs that action. 3. **Iteration:** Steps 2 and 3 repeat until the machine enters a designated halting state.  **Key Concepts:**  * **Determinism:** A Turing Machine is deterministic if the transition function always produces a unique next action for a given state and input symbol. * **Universality:**  A single Turing Machine can be programmed to simulate any other Turing Machine. This means they are capable of performing any computation that a computer can. * **Halting Problem:**  There is no general algorithm that can determine whether a given Turing Machine will eventually halt (stop running) or run forever.  **Significance:**  * **Theoretical Foundation:** Turing Machines provide a formal model for understanding the limits of computation. * **Basis for Modern Computers:** Although not directly implemented in hardware, the principles of Turing Machines underpin the design of modern computers. * **Theoretical Computer Science:** Turing Machines are essential to studying algorithms, computability, and the nature of computation itself.   Let me know if you have any further questions!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"What is Turing Machine please explain in detail?\"\n",
    "ask_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Legacy Langchain Template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are an expert! please reposnd to my question with clear and consise answer', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is DFA in TOC?', additional_kwargs={}, response_metadata={})]\n",
      "Question asked to model is: What is DFA in TOC?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"DFA stands for **Deterministic Finite Automaton** in TOC (Theory of Computation). \\n\\nIt's a mathematical model used to describe simple machines that recognize patterns in strings of symbols.  Think of it as a simplified computer program designed to accept or reject input based on a set of rules. \\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are an expert! please reposnd to my question with clear and consise answer\"),\n",
    "    HumanMessage(content=\"What is DFA in TOC?\")\n",
    "]\n",
    "print(messages)\n",
    "result=model.invoke(messages)\n",
    "human_message=HumanMessage(content=\"What is DFA in TOC?\")\n",
    "# Print only the question from the instance\n",
    "print(f\"Question asked to model is: {human_message.content}\")\n",
    "parser=StrOutputParser()\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LCEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
